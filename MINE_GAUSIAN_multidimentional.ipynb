{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmedadel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "C:\\Users\\ahmedadel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.318787370883925\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "d=100\n",
    "L=50\n",
    "H=50\n",
    "W=50\n",
    "eta_X=np.random.normal(0, 2, (d, d))\n",
    "eta_N=np.random.normal(4, 2, (d, d))\n",
    "eta_Y=eta_X+eta_N\n",
    "meu_X=np.zeros(d)\n",
    "meu_N=np.ones(d)\n",
    "def func(x):\n",
    "    return x\n",
    "\n",
    "def gen_X():\n",
    "    return np.random.multivariate_normal( mean=meu_X,\n",
    "                                  cov=eta_X,\n",
    "                                  size = (L,W,H))\n",
    "def noise():\n",
    "    return np.random.multivariate_normal( mean=meu_N,\n",
    "                                  cov=eta_N,\n",
    "                                 size = (L,W,H))\n",
    "\n",
    "def gen_Y(X,N):\n",
    "    return func(X)+func(N)\n",
    "data_size = 20000\n",
    "X=gen_X()\n",
    "N=noise()\n",
    "y=gen_Y(X,N)\n",
    "mi = 0.5*math.log(np.linalg.det(eta_Y)/np.linalg.det(eta_X),2)\n",
    "print(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50, 50, 100)\n",
      "(50, 50, 50, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma(array, policy,window_size=None, beta=None):\n",
    "    x=np.zeros(len(array))\n",
    "    if policy=='window':\n",
    "        for i in range(0, len(array)):\n",
    "            if i<window_size:\n",
    "                x[i]= np.mean(array[0: i])\n",
    "            else:\n",
    "                x[i]= np.mean(array[i-window_size: i])\n",
    "    elif policy=='weighted':\n",
    "        x[0]=array[0]\n",
    "        for i in range(1, len(array)):\n",
    "               x[i]=x[i-1]*(1-beta)+beta*array[i]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmedadel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "C:\\Users\\ahmedadel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\r"
     ]
    }
   ],
   "source": [
    "H=20\n",
    "n_epochs = 2000\n",
    "data_size = 20000\n",
    "\n",
    "def MINE(x_in, y_in):\n",
    "    \n",
    "    # shuffle and concatenate\n",
    "    y_shuffle = tf.random_shuffle(y_in)\n",
    "    x_conc = tf.concat([x_in, x_in], axis=0)\n",
    "    y_conc = tf.concat([y_in, y_shuffle], axis=0)\n",
    "    \n",
    "    # propagate the forward pass\n",
    "    layerx = layers.linear(x_conc, H)\n",
    "    layery = layers.linear(y_conc, H)\n",
    "    layer2 = tf.nn.relu(layerx + layery)\n",
    "    output = layers.linear(layer2, 1)\n",
    "    \n",
    "    # split in T_xy and T_x_y predictions\n",
    "    N_samples = tf.shape(x_in)[0]\n",
    "    T_xy = output[:N_samples]\n",
    "    T_x_y = output[N_samples:]\n",
    "    # compute the negative loss (maximise loss == minimise -loss)\n",
    "    neg_loss = -(tf.reduce_mean(T_xy, axis=0) - tf.math.log(tf.reduce_mean(tf.math.exp(T_x_y))))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(neg_loss)\n",
    "\n",
    "    return neg_loss, opt\n",
    "\n",
    "# prepare the placeholders for inputs\n",
    "x_in = tf.placeholder(tf.float32, [None, 1], name='x_in')\n",
    "y_in = tf.placeholder(tf.float32, [None, 1], name='y_in')\n",
    "\n",
    "# make the loss and optimisation graphs\n",
    "neg_loss, opt = MINE(x_in, y_in)\n",
    "\n",
    "# start the session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train\n",
    "MIs = []\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # generate the data\n",
    "    x_sample=gen_X()\n",
    "    noise_sample=noise()\n",
    "    Y=gen_Y(x_sample,noise_sample)\n",
    "    X_1D=X.reshape(-1,1)\n",
    "    Y_1D=Y.reshape(-1,1)\n",
    "    print (epoch, end=\"\\r\")\n",
    "\n",
    "    # perform the training step\n",
    "    feed_dict = {x_in:X_1D, y_in:X_1D}\n",
    "    _, neg_l = sess.run([opt, neg_loss], feed_dict=feed_dict)\n",
    "    \n",
    "    # save the loss\n",
    "    MIs.append(-neg_l)\n",
    "\n",
    "mv_av=ma(MIs, policy='weighted', beta=0.01)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([0, len(MIs)], [mi,mi], label='True Mutual Information')\n",
    "ax.plot(range(len(mv_av)), mv_av, label='Moving Average of MINE (window policy)')\n",
    "\n",
    "ax.set_xlabel('training steps')\n",
    "ax.legend(loc='best')\n",
    "fig.savefig('MINE_window.png')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "error=(abs(mv_av[-1]-mi)/mi)*100\n",
    "print('true value:')\n",
    "print(mi)\n",
    "print('calculated value:')\n",
    "print(mv_av[-1])\n",
    "print('error')\n",
    "print(error)\n",
    "print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(d):\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 3, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [4, 4, 4, d, 5], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [2, 2, 2, 5, 5], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmedadel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "C:\\Users\\ahmedadel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\r"
     ]
    }
   ],
   "source": [
    "H=20\n",
    "n_epochs = 2000\n",
    "data_size = 20000\n",
    "\n",
    "def MINE_CNN(x_in, y_in):\n",
    "    \n",
    "    # shuffle and concatenate\n",
    "    y_shuffle = tf.random_shuffle(y_in)\n",
    "    x_conc = tf.concat([x_in, x_in], axis=0)\n",
    "    y_conc = tf.concat([y_in, y_shuffle], axis=0)\n",
    "    \n",
    "    # propagate the forward pass\n",
    "    layerx = layers.linear(x_conc, H)\n",
    "    layery = layers.linear(y_conc, H)\n",
    "    layer2 = tf.nn.relu(layerx + layery)\n",
    "    output = layers.linear(layer2, 1)\n",
    "    \n",
    "    # split in T_xy and T_x_y predictions\n",
    "    N_samples = tf.shape(x_in)[0]\n",
    "    T_xy = output[:N_samples]\n",
    "    T_x_y = output[N_samples:]\n",
    "    # compute the negative loss (maximise loss == minimise -loss)\n",
    "    neg_loss = -(tf.reduce_mean(T_xy, axis=0) - tf.math.log(tf.reduce_mean(tf.math.exp(T_x_y))))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(neg_loss)\n",
    "\n",
    "    return neg_loss, opt\n",
    "\n",
    "# prepare the placeholders for inputs\n",
    "x_in = tf.placeholder(tf.float32, [None, 1], name='x_in')\n",
    "y_in = tf.placeholder(tf.float32, [None, 1], name='y_in')\n",
    "\n",
    "# make the loss and optimisation graphs\n",
    "neg_loss, opt = MINE(x_in, y_in)\n",
    "\n",
    "# start the session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train\n",
    "MIs = []\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # generate the data\n",
    "    x_sample=gen_X()\n",
    "    noise_sample=noise()\n",
    "    Y=gen_Y(x_sample,noise_sample)\n",
    "    X_1D=X.reshape(-1,1)\n",
    "    Y_1D=Y.reshape(-1,1)\n",
    "    print (epoch, end=\"\\r\")\n",
    "\n",
    "    # perform the training step\n",
    "    feed_dict = {x_in:X_1D, y_in:X_1D}\n",
    "    _, neg_l = sess.run([opt, neg_loss], feed_dict=feed_dict)\n",
    "    \n",
    "    # save the loss\n",
    "    MIs.append(-neg_l)\n",
    "\n",
    "mv_av=ma(MIs, policy='weighted', beta=0.01)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([0, len(MIs)], [mi,mi], label='True Mutual Information')\n",
    "ax.plot(range(len(mv_av)), mv_av, label='Moving Average of MINE (window policy)')\n",
    "\n",
    "ax.set_xlabel('training steps')\n",
    "ax.legend(loc='best')\n",
    "fig.savefig('MINE_window.png')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "error=(abs(mv_av[-1]-mi)/mi)*100\n",
    "print('true value:')\n",
    "print(mi)\n",
    "print('calculated value:')\n",
    "print(mv_av[-1])\n",
    "print('error')\n",
    "print(error)\n",
    "print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
