{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *\n",
    "import math \n",
    "import random\n",
    "import itertools\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "d=10\n",
    "L=2000\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1.0 / tf.sqrt(in_dim / 2.0)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "\n",
    "def log2(x):\n",
    "    numerator = tf.log(x)\n",
    "    denominator = tf.log(tf.constant(2, dtype=numerator.dtype),)\n",
    "    return numerator / denominator\n",
    "\n",
    "def func(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def gen_X():\n",
    "    return np.random.multivariate_normal( mean=meu,\n",
    "                                  cov=eta_X,\n",
    "                                  size = L)\n",
    "\n",
    "\n",
    "def gen_Y(X):\n",
    "    return func(X)+ np.random.multivariate_normal( mean=meu, cov=eta_N, size = L)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma(array, policy,window_size=None, beta=None):\n",
    "    x=np.zeros(len(array))\n",
    "    if policy=='window':\n",
    "        for i in range(0, len(array)):\n",
    "            if i<window_size:\n",
    "                x[i]= np.mean(array[0: i])\n",
    "            else:\n",
    "                x[i]= np.mean(array[i-window_size: i])\n",
    "    elif policy=='weighted':\n",
    "        x[0]=array[0]\n",
    "        for i in range(1, len(array)):\n",
    "               x[i]=x[i-1]*(1-beta)+beta*array[i]\n",
    "    elif policy=='None':\n",
    "        for i in range(1, len(array)):\n",
    "             x[i]=array[i] \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MINE(x, y):\n",
    "\n",
    "\n",
    "    L1=20\n",
    "    L2=10\n",
    "    L3=5\n",
    "    L4=5\n",
    "    L5=5\n",
    "    \n",
    "    x_shuffle=tf.random_shuffle(x)\n",
    "    y_shuffle=tf.random_shuffle(y)\n",
    "    \n",
    "    In = tf.concat([x, y], axis=1)\n",
    "\n",
    "    \n",
    "    In_shuffle = tf.concat([x, y_shuffle], axis=1)\n",
    "\n",
    "    \n",
    "    W1=tf.Variable(xavier_init([2*d, L1]))\n",
    "    b1=tf.Variable(tf.zeros([L1]))\n",
    "\n",
    "    layer_joint1=tf.nn.relu(tf.matmul(In,W1)+b1)\n",
    "    layer_marg1=tf.nn.relu(tf.matmul(In_shuffle,W1)+b1)\n",
    "    \n",
    "    Wh2=tf.Variable(xavier_init( [L1,L2]))\n",
    "    bh2=tf.Variable(tf.zeros([L2]))\n",
    "\n",
    "    layer_joint2=tf.nn.relu(tf.matmul(layer_joint1,Wh2)+bh2)\n",
    "    layer_marg2=tf.nn.relu(tf.matmul(layer_marg1,Wh2)+bh2)\n",
    "\n",
    "\n",
    "    Wh3=tf.Variable(xavier_init( [L2,L3]))\n",
    "    bh3=tf.Variable(tf.zeros([L3]))\n",
    "\n",
    "    layer_joint3=tf.nn.relu(tf.matmul(layer_joint2,Wh3)+bh3)\n",
    "    layer_marg3=tf.nn.relu(tf.matmul(layer_marg2,Wh3)+bh3)\n",
    "\n",
    "    Wh4=tf.Variable(xavier_init( [L3,L4]))\n",
    "    bh4=tf.Variable(tf.zeros([L4]))\n",
    "\n",
    "    layer_joint4=tf.nn.relu(tf.matmul(layer_joint3,Wh4)+bh4)\n",
    "    layer_marg4=tf.nn.relu(tf.matmul(layer_marg3,Wh4)+bh4)\n",
    "    \n",
    "    Wh5=tf.Variable(xavier_init( [L4,L5]))\n",
    "    bh5=tf.Variable(tf.zeros([L5]))\n",
    "\n",
    "    layer_joint5=tf.nn.relu(tf.matmul(layer_joint4,Wh5)+bh5)\n",
    "    layer_marg5=tf.nn.relu(tf.matmul(layer_marg4,Wh5)+bh5)\n",
    "    \n",
    "    Wout=tf.Variable(xavier_init( [L5,1]))\n",
    "    bout=tf.Variable(tf.zeros([1]))\n",
    "\n",
    "    out_joint=tf.nn.relu(tf.matmul(layer_joint3,Wout)+bout)\n",
    "    out_marg=tf.nn.relu(tf.matmul(layer_marg3,Wout)+bout)\n",
    "\n",
    "    lower_bound=(tf.reduce_mean(out_joint,axis=0)-log2(tf.reduce_mean(tf.math.pow(2.0,out_marg),axis=0)+10e-5))\n",
    "\n",
    "    theta = [W1,b1,Wh2, bh2,Wh3,bh3, Wh4,bh4 ,Wh5,bh5 ,Wout, bout]\n",
    "\n",
    "    opt = tf.train.AdamOptimizer(0.01).minimize((-lower_bound), var_list=[theta])\n",
    "\n",
    "\n",
    "    return lower_bound, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative achitecture\n",
    "\n",
    "L1=20\n",
    "L2=10\n",
    "L3=5\n",
    "L4=5\n",
    "L5=5\n",
    "def MINE_alt(x_in, y_in):\n",
    "    \n",
    "    # shuffle and concatenate\n",
    "    y_shuffle = tf.random_shuffle(y_in)\n",
    "    x_conc = tf.concat([x_in, x_in], axis=0)\n",
    "    y_conc = tf.concat([y_in, y_shuffle], axis=0)\n",
    "    In=tf.concat([x_conc,y_conc], axis=1)\n",
    "    # propagate the forward pass\n",
    "\n",
    "    layer1 = tf.contrib.layers.fully_connected(In, L1,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    layer2 = tf.contrib.layers.fully_connected(layer1, L2,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    layer3 = tf.contrib.layers.fully_connected(layer2, L3,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    layer4 = tf.contrib.layers.fully_connected(layer3, L4,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    layer5 = tf.contrib.layers.fully_connected(layer4, L5,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    output = tf.contrib.layers.fully_connected(layer5, 1,weights_initializer=layers.xavier_initializer(), activation_fn=None)\n",
    "\n",
    "    \n",
    "    # split in T_xy and T_x_y predictions\n",
    "    N_samples = L\n",
    "    T_xy = output[:N_samples]\n",
    "    T_x_y = output[N_samples:]\n",
    "    # compute the negative loss (maximise loss == minimise -loss)\n",
    "    lower_bound = (tf.reduce_mean(T_xy, axis=0) - log2(tf.reduce_mean(tf.math.pow(2.0,T_x_y)))+10e-5)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(-lower_bound)\n",
    "    \n",
    "    return lower_bound, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahmad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ahmad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "error=np.zeros(batch_size)\n",
    "for i in range(batch_size):\n",
    "\n",
    "    # prepare the placeholders for inputs\n",
    "    x_in = tf.placeholder(tf.float32, [None, d], name='x_in')\n",
    "    y_in = tf.placeholder(tf.float32, [None, d], name='y_in')\n",
    "    # make the loss and optimisation graphs\n",
    "    lower_bound, train_step= MINE(x_in, y_in)\n",
    "\n",
    "    # start the session\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # train\n",
    "    MIs = []\n",
    "\n",
    "    n_epochs = 500000\n",
    "    meu=np.zeros(d)\n",
    "    eta_X=datasets.make_spd_matrix(d, random_state=None)\n",
    "    eta_N=datasets.make_spd_matrix(d, random_state=None)   \n",
    "    eta_Y=eta_X+eta_N\n",
    "\n",
    "\n",
    "    x=gen_X()\n",
    "    y=gen_Y(x)\n",
    "    mi = 0.5*np.log2(np.linalg.det(eta_Y)/np.linalg.det(eta_N))\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # generate the data\n",
    "        x_sample=gen_X()\n",
    "        y_sample=gen_Y(x_sample)\n",
    "\n",
    "\n",
    "        # perform the training step \n",
    "        feed_dict = {x_in:x_sample, y_in:y_sample}\n",
    "        low_bnd,_ = sess.run([lower_bound, train_step], feed_dict=feed_dict)\n",
    "       # print (te)\n",
    "        # save the loss\n",
    "        MIs.append(low_bnd)\n",
    "\n",
    "\n",
    "\n",
    "    mv_av=ma(MIs, policy='None', beta=0.01)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0, len(MIs)], [mi,mi], label='True Mutual Information')\n",
    "    ax.plot(range(len(mv_av)), mv_av, label='Moving Average of MINE')\n",
    "\n",
    "    ax.set_xlabel('training steps')\n",
    "\n",
    "    ax.legend(loc='best')\n",
    "    fig.savefig('MINE_5D_1.png')\n",
    "    fig.show()\n",
    "\n",
    "    m=list(mv_av)\n",
    "    m.remove(max(m))\n",
    "    cMI=max(m)\n",
    "    error[i]=((cMI-mi)/mi)*100\n",
    "\n",
    "\n",
    "    op = open(\"d=10.txt\",\"a\") \n",
    "\n",
    "    op.write( 'True value: {:.4} ; calculated value: {:.4}; error: {:.4}% \\n'\n",
    "        .format(mi, cMI, error)) \n",
    "    op.close() \n",
    "    sess.close()\n",
    "    print((i+1), '%')\n",
    "              \n",
    "error_list=error_tolist()\n",
    "error_list.remove(max(error_list))\n",
    "error_list.remove(min(error_list))\n",
    "\n",
    "error_av=statistics.mean(error_list)\n",
    "              \n",
    "op = open(\"d=10.txt\",\"a\") \n",
    "              \n",
    "op.write( 'Average error: {:.4} % \\n'\n",
    "    .format(error_av)) \n",
    "op.close()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
