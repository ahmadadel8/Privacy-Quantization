{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *\n",
    "import math \n",
    "import random\n",
    "import itertools\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import statistics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "d=5\n",
    "L=2000\n",
    "e=2.71828\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1.0 / tf.sqrt(in_dim / 2.0)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "\n",
    "def log2(x):\n",
    "    numerator = tf.log(x)\n",
    "    denominator = tf.log(tf.constant(2, dtype=numerator.dtype),)\n",
    "    return numerator / denominator\n",
    "\n",
    "def func(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def gen_X():\n",
    "    return np.random.multivariate_normal( mean=meu,\n",
    "                                  cov=eta_X,\n",
    "                                  size = L)\n",
    "\n",
    "\n",
    "def gen_Y(X):\n",
    "    return func(X)+ np.random.multivariate_normal( mean=meu, cov=eta_N, size = L)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma(array, policy,window_size=None, beta=None):\n",
    "    x=np.zeros(len(array))\n",
    "    if policy=='window':\n",
    "        for i in range(0, len(array)):\n",
    "            if i<window_size:\n",
    "                x[i]= np.mean(array[0: i])\n",
    "            else:\n",
    "                x[i]= np.mean(array[i-window_size: i])\n",
    "    elif policy=='weighted':\n",
    "        x[0]=array[0]\n",
    "        for i in range(1, len(array)):\n",
    "               x[i]=x[i-1]*(1-beta)+beta*array[i]\n",
    "    elif policy=='None':\n",
    "        for i in range(1, len(array)):\n",
    "             x[i]=array[i] \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MINE_5(x, y):\n",
    "\n",
    "\n",
    "    L1=20\n",
    "    L2=10\n",
    "    L3=5\n",
    "    L4=5\n",
    "    L5=5\n",
    "\n",
    "    x_shuffle=tf.random_shuffle(x)\n",
    "    y_shuffle=tf.random_shuffle(y)\n",
    "    In = tf.concat([x, y], axis=1)\n",
    "    In_shuffle = tf.concat([x, y_shuffle], axis=1)\n",
    "\n",
    "   # x=tf.reshape(x,[-1,1])\n",
    "  #  y=tf.reshape(y,[-1,1])\n",
    "   # x_shuffle=tf.reshape(x_shuffle,[-1,1])\n",
    "   # y_shuffle=tf.reshape(y_shuffle,[-1,1])\n",
    "\n",
    "\n",
    "    W1=tf.Variable(xavier_init([2*d, L1]))\n",
    "    b1=tf.Variable(tf.zeros([L1]))\n",
    "\n",
    "    layer_joint1=tf.nn.relu(tf.matmul(In,W1)+b1)\n",
    "    layer_marg1=tf.nn.relu(tf.matmul(In_shuffle,W1)+b1)\n",
    "    \n",
    "    Wh2=tf.Variable(xavier_init( [L1,L2]))\n",
    "    bh2=tf.Variable(tf.zeros([L2]))\n",
    "\n",
    "    layer_joint2=tf.nn.relu(tf.matmul(layer_joint1,Wh2)+bh2)\n",
    "    layer_marg2=tf.nn.relu(tf.matmul(layer_marg1,Wh2)+bh2)\n",
    "\n",
    "\n",
    "    Wh3=tf.Variable(xavier_init( [L2,L3]))\n",
    "    bh3=tf.Variable(tf.zeros([L3]))\n",
    "\n",
    "    layer_joint3=tf.nn.relu(tf.matmul(layer_joint2,Wh3)+bh3)\n",
    "    layer_marg3=tf.nn.relu(tf.matmul(layer_marg2,Wh3)+bh3)\n",
    "\n",
    "    Wh4=tf.Variable(xavier_init( [L3,L4]))\n",
    "    bh4=tf.Variable(tf.zeros([L4]))\n",
    "\n",
    "    layer_joint4=tf.nn.relu(tf.matmul(layer_joint3,Wh4)+bh4)\n",
    "    layer_marg4=tf.nn.relu(tf.matmul(layer_marg3,Wh4)+bh4)\n",
    "    \n",
    "    \n",
    "    Wout=tf.Variable(xavier_init( [L4,1]))\n",
    "    bout=tf.Variable(tf.zeros([1]))\n",
    "\n",
    "    out_joint=tf.matmul(layer_joint4,Wout)+bout\n",
    "    out_marg=tf.matmul(layer_marg4,Wout)+bout\n",
    "\n",
    "    lower_bound=(tf.reduce_mean(out_joint,axis=0)-log2(tf.reduce_mean(tf.math.pow(2.0,out_marg),axis=0)+10e-5))\n",
    "\n",
    "    theta = [W1,b1,Wh2, bh2,Wh3,bh3, Wh4,bh4 ,Wout, bout]\n",
    "\n",
    "    opt = tf.train.AdamOptimizer(0.01).minimize((-lower_bound), var_list=[theta])\n",
    "\n",
    "    return lower_bound, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MINE_6(x, y):\n",
    "\n",
    "\n",
    "    L1=20\n",
    "    L2=10\n",
    "    L3=5\n",
    "    L4=5\n",
    "    L5=5\n",
    "\n",
    "    x_shuffle=tf.random_shuffle(x)\n",
    "    y_shuffle=tf.random_shuffle(y)\n",
    "    In = tf.concat([x, y], axis=1)\n",
    "    In_shuffle = tf.concat([x, y_shuffle], axis=1)\n",
    "\n",
    "   # x=tf.reshape(x,[-1,1])\n",
    "  #  y=tf.reshape(y,[-1,1])\n",
    "   # x_shuffle=tf.reshape(x_shuffle,[-1,1])\n",
    "   # y_shuffle=tf.reshape(y_shuffle,[-1,1])\n",
    "\n",
    "\n",
    "    W1=tf.Variable(xavier_init([2*d, L1]))\n",
    "    b1=tf.Variable(tf.zeros([L1]))\n",
    "\n",
    "    layer_joint1=tf.nn.relu(tf.matmul(In,W1)+b1)\n",
    "    layer_marg1=tf.nn.relu(tf.matmul(In_shuffle,W1)+b1)\n",
    "    \n",
    "    Wh2=tf.Variable(xavier_init( [L1,L2]))\n",
    "    bh2=tf.Variable(tf.zeros([L2]))\n",
    "\n",
    "    layer_joint2=tf.nn.relu(tf.matmul(layer_joint1,Wh2)+bh2)\n",
    "    layer_marg2=tf.nn.relu(tf.matmul(layer_marg1,Wh2)+bh2)\n",
    "\n",
    "\n",
    "    Wh3=tf.Variable(xavier_init( [L2,L3]))\n",
    "    bh3=tf.Variable(tf.zeros([L3]))\n",
    "\n",
    "    layer_joint3=tf.nn.relu(tf.matmul(layer_joint2,Wh3)+bh3)\n",
    "    layer_marg3=tf.nn.relu(tf.matmul(layer_marg2,Wh3)+bh3)\n",
    "\n",
    "    Wh4=tf.Variable(xavier_init( [L3,L4]))\n",
    "    bh4=tf.Variable(tf.zeros([L4]))\n",
    "\n",
    "    layer_joint4=tf.nn.relu(tf.matmul(layer_joint3,Wh4)+bh4)\n",
    "    layer_marg4=tf.nn.relu(tf.matmul(layer_marg3,Wh4)+bh4)\n",
    "    \n",
    "    Wh5=tf.Variable(xavier_init( [L4,L5]))\n",
    "    bh5=tf.Variable(tf.zeros([L5]))\n",
    "\n",
    "    layer_joint5=tf.nn.relu(tf.matmul(layer_joint4,Wh5)+bh5)\n",
    "    layer_marg5=tf.nn.relu(tf.matmul(layer_marg4,Wh5)+bh5)\n",
    "    \n",
    "    Wout=tf.Variable(xavier_init( [L5,1]))\n",
    "    bout=tf.Variable(tf.zeros([1]))\n",
    "\n",
    "    out_joint=abs(tf.matmul(layer_joint5,Wout)+bout)\n",
    "    out_marg=abs(tf.matmul(layer_marg5,Wout)+bout)\n",
    "\n",
    "    lower_bound=tf.reduce_mean(out_joint,axis=0)-log2(tf.reduce_mean(tf.math.pow(2.0,out_marg),axis=0))\n",
    "\n",
    "    theta = [W1,b1,Wh2, bh2,Wh3,bh3, Wh4,bh4 ,Wh5,bh5 ,Wout, bout]\n",
    "\n",
    "    opt = tf.train.AdamOptimizer(0.01).minimize((-lower_bound), var_list=[theta])\n",
    "\n",
    "\n",
    "    return lower_bound, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#alternative achitecture\\n\\nL1=20\\nL2=10\\nL3=5\\nL4=5\\nL5=5\\nn_epochs = 2000\\ndata_size = 20000\\ndef MINE_alt(x_in, y_in):\\n    \\n    # shuffle and concatenate\\n    y_shuffle = tf.random_shuffle(y_in)\\n    x_conc = tf.concat([x_in, x_in], axis=0)\\n    y_conc = tf.concat([y_in, y_shuffle], axis=0)\\n    In=tf.concat([x_conc,y_conc], axis=1)\\n    # propagate the forward pass\\n\\n    layer1 = tf.contrib.layers.fully_connected(In, L1,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\\n    layer2 = tf.contrib.layers.fully_connected(layer1, L2,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\\n    layer3 = tf.contrib.layers.fully_connected(layer2, L3,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\\n    layer4 = tf.contrib.layers.fully_connected(layer3, L4,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\\n    layer5 = tf.contrib.layers.fully_connected(layer4, L5,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\\n    output = tf.contrib.layers.fully_connected(layer5, 1,weights_initializer=layers.xavier_initializer(), activation_fn=None)\\n\\n    \\n    # split in T_xy and T_x_y predictions\\n    N_samples = L\\n    T_xy = output[:N_samples]\\n    T_x_y = output[N_samples:]\\n    # compute the negative loss (maximise loss == minimise -loss)\\n    lower_bound = (tf.reduce_mean(T_xy, axis=0) - log2(tf.reduce_mean(tf.math.pow(2.0,T_x_y)))+10e-5)\\n    opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(-neg_loss)\\n    \\n    return lower_bound, opt\\n        '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#alternative achitecture\n",
    "\n",
    "L1=20\n",
    "L2=10\n",
    "L3=5\n",
    "L4=5\n",
    "L5=5\n",
    "n_epochs = 2000\n",
    "data_size = 20000\n",
    "def MINE_alt(x_in, y_in):\n",
    "    \n",
    "    # shuffle and concatenate\n",
    "    y_shuffle = tf.random_shuffle(y_in)\n",
    "    x_conc = tf.concat([x_in, x_in], axis=0)\n",
    "    y_conc = tf.concat([y_in, y_shuffle], axis=0)\n",
    "    In=tf.concat([x_conc,y_conc], axis=1)\n",
    "    # propagate the forward pass\n",
    "\n",
    "    layer1 = tf.contrib.layers.fully_connected(In, L1,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    layer2 = tf.contrib.layers.fully_connected(layer1, L2,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    layer3 = tf.contrib.layers.fully_connected(layer2, L3,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    layer4 = tf.contrib.layers.fully_connected(layer3, L4,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    layer5 = tf.contrib.layers.fully_connected(layer4, L5,weights_initializer=layers.xavier_initializer(), activation_fn=tf.nn.tanh)\n",
    "    output = tf.contrib.layers.fully_connected(layer5, 1,weights_initializer=layers.xavier_initializer(), activation_fn=None)\n",
    "\n",
    "    \n",
    "    # split in T_xy and T_x_y predictions\n",
    "    N_samples = L\n",
    "    T_xy = output[:N_samples]\n",
    "    T_x_y = output[N_samples:]\n",
    "    # compute the negative loss (maximise loss == minimise -loss)\n",
    "    lower_bound = (tf.reduce_mean(T_xy, axis=0) - log2(tf.reduce_mean(tf.math.pow(2.0,T_x_y)))+10e-5)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(-neg_loss)\n",
    "    \n",
    "    return lower_bound, opt\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahmedadel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ahmedadel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "99.9900000000000143\n",
      "1 %\n",
      "99.9900000000000143\n",
      "2 %\n",
      "99.9900000000000143\n",
      "3 %\n",
      "99.9900000000000143\n",
      "4 %\n",
      "99.9900000000000143\n",
      "5 %\n",
      "99.9900000000000143\n",
      "6 %\n",
      "99.9900000000000143\n",
      "7 %\n",
      "99.9900000000000143\n",
      "8 %\n",
      "99.9900000000000143\n",
      "9 %\n",
      "99.9900000000000143\n",
      "10 %\n",
      "99.9900000000000143\n",
      "11 %\n",
      "99.9900000000000143\n",
      "12 %\n",
      "99.9900000000000143\n",
      "13 %\n",
      "99.9900000000000143\n",
      "14 %\n",
      "99.9900000000000143\n",
      "15 %\n",
      "99.9900000000000143\n",
      "16 %\n",
      "99.9900000000000143\n",
      "17 %\n",
      "99.9900000000000143\n",
      "18 %\n",
      "99.9900000000000143\n",
      "19 %\n",
      "99.9900000000000143\n",
      "20 %\n",
      "99.9900000000000143\n",
      "21 %\n",
      "99.9900000000000143\n",
      "22 %\n",
      "99.9900000000000143\n",
      "23 %\n",
      "99.9900000000000143\n",
      "24 %\n",
      "99.9900000000000143\n",
      "25 %\n",
      "99.9900000000000143\n",
      "26 %\n",
      "99.9900000000000143\n",
      "27 %\n",
      "99.9900000000000143\n",
      "28 %\n",
      "99.9900000000000143\n",
      "29 %\n",
      "99.9900000000000143\n",
      "30 %\n",
      "99.9900000000000143\n",
      "31 %\n",
      "99.9900000000000143\n",
      "32 %\n",
      "99.9900000000000143\n",
      "33 %\n",
      "99.9900000000000143\n",
      "34 %\n",
      "99.9900000000000143\n",
      "35 %\n",
      "99.9900000000000143\n",
      "36 %\n",
      "99.9900000000000143\n",
      "37 %\n",
      "99.9900000000000143\n",
      "38 %\n",
      "99.9900000000000143\n",
      "39 %\n",
      "99.9900000000000143\n",
      "40 %\n",
      "99.9900000000000143\n",
      "41 %\n",
      "99.9900000000000143\n",
      "42 %\n",
      "99.9900000000000143\n",
      "43 %\n",
      "99.9900000000000143\n",
      "44 %\n",
      "99.9900000000000143\n",
      "45 %\n",
      "99.9900000000000143\n",
      "46 %\n",
      "99.9900000000000143\n",
      "47 %\n",
      "99.9900000000000143\n",
      "48 %\n",
      "99.9900000000000143\n",
      "49 %\n",
      "99.9900000000000143\n",
      "50 %\n",
      "99.9900000000000143\n",
      "51 %\n",
      "99.9900000000000143\n",
      "52 %\n",
      "99.9900000000000143\n",
      "53 %\n",
      "99.9900000000000143\n",
      "54 %\n",
      "99.9900000000000143\n",
      "55 %\n",
      "99.9900000000000143\n",
      "56 %\n",
      "99.9900000000000143\n",
      "57 %\n",
      "99.9900000000000143\n",
      "58 %\n",
      "99.9900000000000143\n",
      "59 %\n",
      "99.9900000000000143\n",
      "60 %\n",
      "99.9900000000000143\n",
      "61 %\n",
      "99.9900000000000143\n",
      "62 %\n",
      "99.9900000000000143\n",
      "63 %\n",
      "99.9900000000000143\n",
      "64 %\n",
      "99.9900000000000143\n",
      "65 %\n",
      "99.9900000000000143\n",
      "66 %\n",
      "99.9900000000000143\n",
      "67 %\n",
      "99.9900000000000143\n",
      "68 %\n",
      "99.9900000000000143\n",
      "69 %\n",
      "99.9900000000000143\n",
      "70 %\n",
      "99.9900000000000143\n",
      "71 %\n",
      "99.9900000000000143\n",
      "72 %\n",
      "99.9900000000000143\n",
      "73 %\n",
      "99.9900000000000143\n",
      "74 %\n",
      "99.9900000000000143\n",
      "75 %\n",
      "99.9900000000000143\n",
      "76 %\n",
      "99.9900000000000143\n",
      "77 %\n",
      "99.9900000000000143\n",
      "78 %\n",
      "99.9900000000000143\n",
      "79 %\n",
      "99.9900000000000143\n",
      "80 %\n",
      "99.9900000000000143\n",
      "81 %\n",
      "99.9900000000000143\n",
      "82 %\n",
      "99.9900000000000143\n",
      "83 %\n",
      "99.9900000000000143\n",
      "84 %\n",
      "99.9900000000000143\n",
      "85 %\n",
      "99.9900000000000143\n",
      "86 %\n",
      "99.9900000000000143\n",
      "87 %\n",
      "99.9900000000000143\n",
      "88 %\n",
      "99.9900000000000143\n",
      "89 %\n",
      "99.9900000000000143\n",
      "90 %\n",
      "99.9900000000000143\n",
      "91 %\n",
      "99.9900000000000143\n",
      "92 %\n",
      "99.9900000000000143\n",
      "93 %\n",
      "99.9900000000000143\n",
      "94 %\n",
      "99.9900000000000143\n",
      "95 %\n",
      "99.9900000000000143\n",
      "96 %\n",
      "99.9900000000000143\n",
      "97 %\n",
      "99.9900000000000143\n",
      "98 %\n",
      "99.9900000000000143\n",
      "99 %\n",
      "99.9900000000000143\n",
      "100 %\n",
      "99.9900000000000143\n",
      "101 %\n",
      "99.9900000000000143\n",
      "102 %\n",
      "99.9900000000000143\n",
      "103 %\n",
      "99.9900000000000143\n",
      "104 %\n",
      "99.9900000000000143\n",
      "105 %\n",
      "99.9900000000000143\n",
      "106 %\n",
      "99.9900000000000143\n",
      "107 %\n",
      "99.9900000000000143\n",
      "108 %\n",
      "99.9900000000000143\n",
      "109 %\n",
      "99.9900000000000143\n",
      "110 %\n",
      "99.9900000000000143\n",
      "111 %\n",
      "99.9900000000000143\n",
      "112 %\n",
      "99.9900000000000143\n",
      "113 %\n",
      "99.9900000000000143\n",
      "114 %\n",
      "99.9900000000000143\n",
      "115 %\n",
      "99.9900000000000143\n",
      "116 %\n",
      "99.9900000000000143\n",
      "117 %\n",
      "99.9900000000000143\n",
      "118 %\n",
      "99.9900000000000143\n",
      "119 %\n",
      "99.9900000000000143\n",
      "120 %\n",
      "99.9900000000000143\n",
      "121 %\n",
      "99.9900000000000143\n",
      "122 %\n",
      "99.9900000000000143\n",
      "123 %\n",
      "99.9900000000000143\n",
      "124 %\n",
      "99.9900000000000143\n",
      "125 %\n",
      "99.9900000000000143\n",
      "126 %\n",
      "99.9900000000000143\n",
      "127 %\n",
      "99.9900000000000143\n",
      "128 %\n",
      "99.9900000000000143\n",
      "129 %\n",
      "99.9900000000000143\n",
      "130 %\n",
      "99.9900000000000143\n",
      "131 %\n",
      "99.9900000000000143\n",
      "132 %\n",
      "99.9900000000000143\n",
      "133 %\n",
      "99.9900000000000143\n",
      "134 %\n",
      "99.9900000000000143\n",
      "135 %\n",
      "99.9900000000000143\n",
      "136 %\n",
      "99.9900000000000143\n",
      "137 %\n",
      "99.9900000000000143\n",
      "138 %\n",
      "99.9900000000000143\n",
      "139 %\n",
      "99.9900000000000143\n",
      "140 %\n",
      "99.9900000000000143\n",
      "141 %\n",
      "99.9900000000000143\n",
      "142 %\n",
      "99.9900000000000143\n",
      "143 %\n",
      "99.9900000000000143\n",
      "144 %\n",
      "99.9900000000000143\n",
      "145 %\n",
      "99.9900000000000143\n",
      "146 %\n",
      "99.9900000000000143\n",
      "147 %\n",
      "99.9900000000000143\n",
      "148 %\n",
      "99.9900000000000143\n",
      "149 %\n",
      "99.9900000000000143\n",
      "150 %\n",
      "99.9900000000000143\n",
      "151 %\n",
      "99.9900000000000143\n",
      "152 %\n",
      "99.9900000000000143\n",
      "153 %\n",
      "99.9900000000000143\n",
      "154 %\n",
      "99.9900000000000143\n",
      "155 %\n",
      "99.9900000000000143\n",
      "156 %\n",
      "99.9900000000000143\n",
      "157 %\n",
      "99.9900000000000143\n",
      "158 %\n",
      "99.9900000000000143\n",
      "159 %\n",
      "99.9900000000000143\n",
      "160 %\n",
      "99.9900000000000143\n",
      "161 %\n",
      "99.9900000000000143\n",
      "162 %\n",
      "99.9900000000000143\n",
      "163 %\n",
      "99.9900000000000143\n",
      "164 %\n",
      "99.9900000000000143\n",
      "165 %\n",
      "99.9900000000000143\n",
      "166 %\n",
      "99.9900000000000143\n",
      "167 %\n",
      "99.9900000000000143\n",
      "168 %\n",
      "99.9900000000000143\n",
      "169 %\n",
      "99.9900000000000143\n",
      "170 %\n",
      "99.9900000000000143\n",
      "171 %\n",
      "99.9900000000000143\n",
      "172 %\n",
      "99.9900000000000143\n",
      "173 %\n",
      "99.9900000000000143\n",
      "174 %\n",
      "99.9900000000000143\n",
      "175 %\n",
      "99.9900000000000143\n",
      "176 %\n",
      "99.9900000000000143\n",
      "177 %\n",
      "99.9900000000000143\n",
      "178 %\n",
      "99.9900000000000143\n",
      "179 %\n",
      "99.9900000000000143\n",
      "180 %\n",
      "99.9900000000000143\n",
      "181 %\n",
      "99.9900000000000143\n",
      "182 %\n",
      "99.9900000000000143\n",
      "183 %\n",
      "99.9900000000000143\n",
      "184 %\n",
      "99.9900000000000143\n",
      "185 %\n",
      "99.9900000000000143\n",
      "186 %\n",
      "99.9900000000000143\n",
      "187 %\n",
      "99.9900000000000143\n",
      "188 %\n",
      "99.9900000000000143\n",
      "189 %\n",
      "99.9900000000000143\n",
      "190 %\n",
      "99.9900000000000143\n",
      "191 %\n",
      "99.9900000000000143\n",
      "192 %\n",
      "99.9900000000000143\n",
      "193 %\n",
      "99.9900000000000143\n",
      "194 %\n",
      "99.9900000000000143\n",
      "195 %\n",
      "99.9900000000000143\n",
      "196 %\n",
      "99.9900000000000143\n",
      "197 %\n",
      "99.9900000000000143\n",
      "198 %\n",
      "99.9900000000000143\n",
      "199 %\n",
      "99.9900000000000143\n",
      "200 %\n",
      "99.9900000000000143\n",
      "201 %\n",
      "99.9900000000000143\n",
      "202 %\n",
      "99.9900000000000143\n",
      "203 %\n",
      "99.9900000000000143\n",
      "204 %\n",
      "99.9900000000000143\n",
      "205 %\n",
      "99.9900000000000143\n",
      "206 %\n",
      "99.9900000000000143\n",
      "207 %\n",
      "99.9900000000000143\n",
      "208 %\n",
      "99.9900000000000143\n",
      "209 %\n",
      "99.9900000000000143\n",
      "210 %\n",
      "99.9900000000000143\n",
      "211 %\n",
      "99.9900000000000143\n",
      "212 %\n",
      "99.9900000000000143\n",
      "213 %\n",
      "99.9900000000000143\n",
      "214 %\n",
      "99.9900000000000143\n",
      "215 %\n",
      "99.9900000000000143\n",
      "216 %\n",
      "99.9900000000000143\n",
      "217 %\n",
      "99.9900000000000143\n",
      "218 %\n",
      "99.9900000000000143\n",
      "219 %\n",
      "99.9900000000000143\n",
      "220 %\n",
      "99.9900000000000143\n",
      "221 %\n",
      "99.9900000000000143\n",
      "222 %\n",
      "99.9900000000000143\n",
      "223 %\n",
      "99.9900000000000143\n",
      "224 %\n",
      "99.9900000000000143\n",
      "225 %\n",
      "99.9900000000000143\n",
      "226 %\n",
      "99.9900000000000143\n",
      "227 %\n",
      "99.9900000000000143\n",
      "228 %\n",
      "99.9900000000000143\n",
      "229 %\n",
      "99.9900000000000143\n",
      "230 %\n",
      "99.9900000000000143\n",
      "231 %\n",
      "99.9900000000000143\n",
      "232 %\n",
      "99.9900000000000143\n",
      "233 %\n",
      "99.9900000000000143\n",
      "234 %\n",
      "99.9900000000000143\n",
      "235 %\n",
      "99.9900000000000143\n",
      "236 %\n",
      "99.9900000000000143\n",
      "237 %\n",
      "99.9900000000000143\n",
      "238 %\n",
      "99.9900000000000143\n",
      "239 %\n",
      "99.9900000000000143\n",
      "240 %\n",
      "99.9900000000000143\n",
      "241 %\n",
      "99.9900000000000143\n",
      "242 %\n",
      "99.9900000000000143\n",
      "243 %\n",
      "99.9900000000000143\n",
      "244 %\n",
      "99.9900000000000143\n",
      "245 %\n",
      "99.9900000000000143\n",
      "246 %\n",
      "99.9900000000000143\n",
      "247 %\n",
      "99.9900000000000143\n",
      "248 %\n",
      "99.9900000000000143\n",
      "249 %\n",
      "99.9900000000000143\n",
      "250 %\n",
      "99.9900000000000143\n",
      "251 %\n",
      "99.9900000000000143\n",
      "252 %\n",
      "99.9900000000000143\n",
      "253 %\n",
      "99.9900000000000143\n",
      "254 %\n",
      "99.9900000000000143\n",
      "255 %\n",
      "99.9900000000000143\n",
      "256 %\n",
      "99.9900000000000143\n",
      "257 %\n",
      "99.9900000000000143\n",
      "258 %\n",
      "99.9900000000000143\n",
      "259 %\n",
      "99.9900000000000143\n",
      "260 %\n",
      "99.9900000000000143\n",
      "261 %\n",
      "99.9900000000000143\n",
      "262 %\n",
      "99.9900000000000143\n",
      "263 %\n",
      "99.9900000000000143\n",
      "264 %\n",
      "99.9900000000000143\n",
      "265 %\n",
      "99.9900000000000143\n",
      "266 %\n",
      "99.9900000000000143\n",
      "267 %\n",
      "99.9900000000000143\n",
      "268 %\n",
      "99.9900000000000143\n",
      "269 %\n",
      "99.9900000000000143\n",
      "270 %\n",
      "99.9900000000000143\n",
      "271 %\n",
      "99.9900000000000143\n",
      "272 %\n",
      "99.9900000000000143\n",
      "273 %\n",
      "99.9900000000000143\n",
      "274 %\n",
      "99.9900000000000143\n",
      "275 %\n",
      "99.9900000000000143\n",
      "276 %\n",
      "99.9900000000000143\n",
      "277 %\n",
      "99.9900000000000143\n",
      "278 %\n",
      "99.9900000000000143\n",
      "279 %\n",
      "99.9900000000000143\n",
      "280 %\n",
      "99.9900000000000143\n",
      "281 %\n",
      "99.9900000000000143\n",
      "282 %\n",
      "99.9900000000000143\n",
      "283 %\n",
      "99.9900000000000143\n",
      "284 %\n",
      "99.9900000000000143\n",
      "285 %\n",
      "99.9900000000000143\n",
      "286 %\n",
      "99.9900000000000143\n",
      "287 %\n",
      "99.9900000000000143\n",
      "288 %\n",
      "99.9900000000000143\n",
      "289 %\n",
      "99.9900000000000143\n",
      "290 %\n",
      "99.9900000000000143\n",
      "291 %\n",
      "99.9900000000000143\n",
      "292 %\n",
      "99.9900000000000143\n",
      "293 %\n",
      "99.9900000000000143\n",
      "294 %\n",
      "99.9900000000000143\n",
      "295 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9900000000000143\n",
      "296 %\n",
      "99.9900000000000143\n",
      "297 %\n",
      "99.9900000000000143\n",
      "298 %\n",
      "99.9900000000000143\n",
      "299 %\n",
      "99.9900000000000143\n",
      "300 %\n",
      "99.9900000000000143\n",
      "301 %\n",
      "99.9900000000000143\n",
      "302 %\n",
      "99.9900000000000143\n",
      "303 %\n",
      "99.9900000000000143\n",
      "304 %\n",
      "99.9900000000000143\n",
      "305 %\n",
      "99.9900000000000143\n",
      "306 %\n",
      "99.9900000000000143\n",
      "307 %\n",
      "99.9900000000000143\n",
      "308 %\n",
      "99.9900000000000143\n",
      "309 %\n",
      "99.9900000000000143\n",
      "310 %\n",
      "99.9900000000000143\n",
      "311 %\n",
      "99.9900000000000143\n",
      "312 %\n",
      "99.9900000000000143\n",
      "313 %\n",
      "99.9900000000000143\n",
      "314 %\n",
      "99.9900000000000143\n",
      "315 %\n",
      "99.9900000000000143\n",
      "316 %\n",
      "99.9900000000000143\n",
      "317 %\n",
      "99.9900000000000143\n",
      "318 %\n",
      "99.9900000000000143\n",
      "319 %\n",
      "99.9900000000000143\n",
      "320 %\n",
      "99.9900000000000143\n",
      "321 %\n",
      "99.9900000000000143\n",
      "322 %\n",
      "99.9900000000000143\n",
      "323 %\n",
      "99.9900000000000143\n",
      "324 %\n",
      "99.9900000000000143\n",
      "325 %\n",
      "99.9900000000000143\n",
      "326 %\n",
      "99.9900000000000143\n",
      "327 %\n",
      "99.9900000000000143\n",
      "328 %\n",
      "99.9900000000000143\n",
      "329 %\n",
      "99.9900000000000143\n",
      "330 %\n",
      "99.9900000000000143\n",
      "331 %\n",
      "99.9900000000000143\n",
      "332 %\n",
      "99.9900000000000143\n",
      "333 %\n",
      "99.9900000000000143\n",
      "334 %\n",
      "99.9900000000000143\n",
      "335 %\n",
      "99.9900000000000143\n",
      "336 %\n",
      "99.9900000000000143\n",
      "337 %\n",
      "99.9900000000000143\n",
      "338 %\n",
      "99.9900000000000143\n",
      "339 %\n",
      "99.9900000000000143\n",
      "340 %\n",
      "99.9900000000000143\n",
      "341 %\n",
      "99.9900000000000143\n",
      "342 %\n",
      "99.9900000000000143\n",
      "343 %\n",
      "99.9900000000000143\n",
      "344 %\n",
      "99.9900000000000143\n",
      "345 %\n",
      "99.9900000000000143\n",
      "346 %\n",
      "99.9900000000000143\n",
      "347 %\n",
      "99.9900000000000143\n",
      "348 %\n",
      "99.9900000000000143\n",
      "349 %\n",
      "99.9900000000000143\n",
      "350 %\n",
      "99.9900000000000143\n",
      "351 %\n",
      "99.9900000000000143\n",
      "352 %\n",
      "99.9900000000000143\n",
      "353 %\n",
      "99.9900000000000143\n",
      "354 %\n",
      "99.9900000000000143\n",
      "355 %\n",
      "99.9900000000000143\n",
      "356 %\n",
      "99.9900000000000143\n",
      "357 %\n",
      "99.9900000000000143\n",
      "358 %\n",
      "99.9900000000000143\n",
      "359 %\n",
      "99.9900000000000143\n",
      "360 %\n",
      "99.9900000000000143\n",
      "361 %\n",
      "99.9900000000000143\n",
      "362 %\n",
      "99.9900000000000143\n",
      "363 %\n",
      "99.9900000000000143\n",
      "364 %\n",
      "99.9900000000000143\n",
      "365 %\n",
      "99.9900000000000143\n",
      "366 %\n",
      "99.9900000000000143\n",
      "367 %\n",
      "99.9900000000000143\n",
      "368 %\n",
      "99.9900000000000143\n",
      "369 %\n",
      "99.9900000000000143\n",
      "370 %\n",
      "99.9900000000000143\n",
      "371 %\n",
      "99.9900000000000143\n",
      "372 %\n",
      "99.9900000000000143\n",
      "373 %\n",
      "99.9900000000000143\n",
      "374 %\n",
      "99.9900000000000143\n",
      "375 %\n",
      "99.9900000000000143\n",
      "376 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d693f886151c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# start the session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10000\n",
    "\n",
    "# train\n",
    "batch_size=5000\n",
    "d=10\n",
    "error_6=np.zeros(batch_size)\n",
    "for i in range (batch_size):\n",
    "    MIs = []\n",
    "    meu=np.zeros(d)\n",
    "    eta_X=datasets.make_spd_matrix(d, random_state=None)\n",
    "    eta_N=datasets.make_spd_matrix(d, random_state=None)   \n",
    "    eta_Y=eta_X+eta_N\n",
    "\n",
    "\n",
    "    x=gen_X()\n",
    "    y=gen_Y(x)\n",
    "    mi = 0.5*np.log2(np.linalg.det(eta_Y)/np.linalg.det(eta_N))\n",
    "\n",
    "\n",
    "    # prepare the placeholders for inputs\n",
    "    x_in = tf.placeholder(tf.float32, [None, d], name='x_in')\n",
    "    y_in = tf.placeholder(tf.float32, [None, d], name='y_in')\n",
    "    # make the loss and optimisation graphs\n",
    "    lower_bound, train_step= MINE_6(x_in, y_in)\n",
    "\n",
    "    # start the session\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # train\n",
    "    MIs = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # generate the data\n",
    "        x_sample=gen_X()\n",
    "        y_sample=gen_Y(x_sample)\n",
    "\n",
    "\n",
    "        # perform the training step \n",
    "        feed_dict = {x_in:x_sample, y_in:y_sample}\n",
    "        low_bnd,_ = sess.run([lower_bound, train_step], feed_dict=feed_dict)\n",
    "        # print (te)\n",
    "        # save the loss\n",
    "        MIs.append(low_bnd)\n",
    "\n",
    "        print(epoch/n_epochs*100,end='\\r')\n",
    "    print('\\r')\n",
    "\n",
    "\n",
    "    mv_av=ma(MIs, policy='weighted', beta=0.01)\n",
    "    error_6[i]=((np.amax(mv_av)-mi)/mi)*100\n",
    "    \n",
    "        \n",
    "    op = open(\"d={d}.txt\".format(d=d),\"a\") \n",
    "\n",
    "    op.write( '{:} True value: {:.4} ; calculated value: {:.4}; error: {:.4}%; Average{:.4}% \\n'\n",
    "    .format(i+1, mi, np.amax(mv_av), error_6[i], np.mean(error_6[:i+1])) )\n",
    "    op.close() \n",
    "    sess.close()\n",
    "    print (i+1, '%')\n",
    "error_6=error_6.tolist()\n",
    "error_6.remove(max(error_6))\n",
    "error_6.remove(min(error_6))\n",
    "error_av_6=statistics.mean(error_6)\n",
    "\n",
    "\n",
    "\n",
    "op = open(\"d={d}.txt\".format(d=d),\"a\") \n",
    "\n",
    "op.write( 'Average error:{:.4} \\n'\n",
    ".format(error_av_6))\n",
    "op.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "err_file = \"data.csv\"\n",
    "\n",
    "#Assuming res is a flat list\n",
    "with open(err_file, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in error_6:\n",
    "        writer.writerow([val])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
